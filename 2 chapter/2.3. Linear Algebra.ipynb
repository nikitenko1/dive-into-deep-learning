{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176d34d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90de2a",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 30px; color: magenta\"> 2.3. Linear Algebra</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2bb545",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.1. Scalars</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23813ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The symbol (pronounced “in”) denotes membership in a set. \n",
    "# For example, indicates that and are variables that can only take values or.\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17ebb5",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.2. Vectors</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1471636b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1a2d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4cd37ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To indicate that a vector contains elements, we write. Formally, we call the dimensionality of the vector.\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a91f092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d5666",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.3. Matrices</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a76708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92330ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we exchange a matrix’s rows and columns, the result is called its transpose.\n",
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b975949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Symmetric matrices are the subset of square matrices that are equal to their own transposes.\n",
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "A == A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7716f8",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.4. Tensors</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1fb5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31422483",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.5. Basic Properties of Tensor Arithmetic</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8eeb2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()  # Assign a copy of A to B by allocating new memory\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9edd8500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The elementwise product of two matrices is called their Hadamard product (denoted).\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9724e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d74280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98480c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding or multiplying a scalar and a tensor produces a result with the same shape as the original tensor.\n",
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4ac2e",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.6. Reduction</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db20633c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor(3.))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bbd25d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), tensor(15.))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()\n",
    "# tensor([[0., 1., 2.],\n",
    "#         [3., 4., 5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247015f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To sum over all elements along the rows (axis 0), we specify axis=0 in sum\n",
    "A.shape, A.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f41ccc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying axis=1 will reduce the column dimension (axis 1) by summing up elements of all the columns.\n",
    "A.shape, A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ba98341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum()  # Same as A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f1589cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5000), tensor(2.5000))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A related quantity is the mean, also called the average.\n",
    "A.mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cf02a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Likewise, the function for calculating the mean can also reduce a tensor along specific axes.\n",
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4bf0c3",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.7. Non-Reduction Sum</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ef6b100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.],\n",
       "         [12.]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9185fffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00e60a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to calculate the cumulative sum of elements of A along some axis, say axis=0 (row by row), \n",
    "# we can call the cumsum function.\n",
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7c4fc",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.8. Dot Products</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0099962c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa227e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalently, we can calculate the dot product of two vectors \n",
    "# by performing an elementwise multiplication followed by a sum:\n",
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b322d432",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.9. Matrix–Vector Products</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a86cf6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]), tensor([ 5., 14.]), tensor([ 5., 14.]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x), A@x\n",
    "# To express a matrix–vector product in code, we use the mv function.\n",
    "\n",
    "# Python has a convenience operator @ that can execute both matrix–vector \n",
    "# and matrix–matrix products (depending on its arguments).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15231e14",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.10. Matrix–Matrix Multiplication</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dfff651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(3, 4)\n",
    "torch.mm(A, B), A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd8b29",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.11. Norms</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcd85b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bba0c2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e7a6d",
   "metadata": {},
   "source": [
    "<p style=\"font-family:ComicSansMS; font-size: 24px; color: orange\"> 2.3.12. Discussion</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe9068",
   "metadata": {},
   "source": [
    "> Scalars, vectors, matrices, and tensors are the basic mathematical objects used in linear algebra and have zero, one, two, and an arbitrary number of axes, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35868d76",
   "metadata": {},
   "source": [
    "> Tensors can be sliced or reduced along specified axes via indexing, or operations such as sum and mean, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964eda6",
   "metadata": {},
   "source": [
    "> Elementwise products are called Hadamard products. By contrast, dot products, matrix–vector products, and matrix–matrix products are not elementwise operations and in general return objects having shapes that are different from the the operands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051cddd",
   "metadata": {},
   "source": [
    "> Norms capture various notions of the magnitude of a vector (or matrix), and are commonly applied to the difference of two vectors to measure their distance apart."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
